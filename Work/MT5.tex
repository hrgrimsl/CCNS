\documentclass{article}
\title{Homework 5}
\author{Harper Grimsley}
\usepackage{amsmath}
\usepackage{fullpage}
\begin{document}
\maketitle
\section*{4.1}
\subsection*{3}
The action of A on x is given as:
$$Ax = \begin{pmatrix}x_2\\x_3\\x_4\\-\alpha_4x_1-\alpha_3x_2-\alpha_2x_3-\alpha_1x_4\end{pmatrix}$$
If $x_1 = 0$, then $x_2 = 0$ or Ax is not a scalar multiple of x.  Similarly, if $x_2 = 0$, $x_3$ must be 0. Finally, $x_4$ must be 0 if $x_3$ is 0.  Thus, if $x_1 = 0$, x cannot be a non-trivial eigenvector.   
\\
If $x_1 =1$ and x is an eigenvector, $x_2 = \lambda$, $x_3 = \lambda^2$, and $x_4 = \lambda^3$.\\
The characteristic polynomial of A is:  
$$det(\lambda I-A) = \lambda^4 + \alpha_1\lambda^3+\alpha_2\lambda^2+\alpha_3\lambda+\alpha_4$$
A has four linearly independent eigenvectors if and only if the characteristic polynomial gives four eigenvalues.  To satisfy the earlier conditions, any solution must take the form:
$$\lambda x_1 \begin{pmatrix}1\\\lambda\\\lambda^2\\\lambda^3\end{pmatrix}$$ 
Thus, a single $\lambda$ gives only one spanning eigenvector, so having fewer than 4 eigenvalues gives fewer than 4 eigenvectors.  If we have 4 eigenvalues we are already guarenteed 4 eigenvectors.
\section*{4.2}
\subsection*{2}
By inspection,
$$x^{(n)} = Ax^{(n)} = \begin{pmatrix}1&1\\1&0\end{pmatrix}x^{(n-1)} = A^nx^{(0)}=\begin{pmatrix}1&1\\1&0\end{pmatrix}^n\begin{pmatrix}1\\1\end{pmatrix}$$
A has characteristic polynomial $\lambda^2-\lambda-1=0$ with eigenvalues $\frac{1+\sqrt{5}}{2}$, $\frac{1-\sqrt{5}}{2}$ with respective eigenvectors $(\frac{1+\sqrt{5}}{2},1)^T$ and $(\frac{1-\sqrt{5}}{2},1)^T$
We recognize that we can similarity transform as:
$$A^n = \frac{1}{\sqrt{5}}\begin{pmatrix}\frac{1+\sqrt{5}}{2}&\frac{1-\sqrt{5}}{2}\\1&1\end{pmatrix}\begin{pmatrix}(\frac{1+\sqrt{5}}{2})^n&0\\0&(\frac{1-\sqrt{5}}{2})^n\end{pmatrix}\begin{pmatrix}1&\frac{\sqrt{5}-1}{2}\\-1&\frac{1+\sqrt{5}}{2}\end{pmatrix}$$
Acting this product on $x_0 = (1,1)^T$ gives
$$x^{(n)} = A^nx^{(0)} = \frac{1}{\sqrt{5}}\begin{pmatrix}(\frac{1+\sqrt{5}}{2})^{n+1}+(\frac{1+\sqrt{5}}{2})^{n}- (\frac{1-\sqrt{5}}{2})^{n+1}-(\frac{1+\sqrt{5}}{2})^n\\ (\frac{1+\sqrt{5}}{2})^{n}+(\frac{1+\sqrt{5}}{2})^{n-1}- (\frac{1-\sqrt{5}}{2})^{n}-(\frac{1+\sqrt{5}}{2})^{n-1}\end{pmatrix}$$
\subsection*{3}  If $Au^i=\lambda_iu^i$, then $$BT^{-1}u^iT=T^{-1}ATT^{-1}u^iT=T^{-1}A\lambda_iT = \lambda_iB$$ so any eigenvector of A has a similarity-transformed eigenvector in B.  The similarity transformed eigenvectors must still be linearly independent, because 
$$0 = \sum \alpha_iT^{-1}u^iT = \sum T^{-1}\alpha_iu^iT$$
and if $\alpha_i\neq 0$ for two or more i, 
$$0 = \sum \alpha_iu^i$$
for those $\alpha_i\neq 0$ and the $u^i$'s are linearly dependent.
\subsection*{6}
Let $B = T^{-1}AT$ and $C = S^{-1}BS$.  Then $C = S^{-1}T^{-1}ATS$.  $S^{-1}T^{-1}TS = I$, so if $TS = R$, $C = R^{-1}AR$ and is a similarity transform of A.

\section*{4.3}
\subsection*{1}
We recognize this sum as $c_2$, which is equal to
$$\begin{vmatrix}1&2\\8&7\end{vmatrix}+\begin{vmatrix}1&3\\1&5\end{vmatrix}+\begin{vmatrix}1&4\\2&7\end{vmatrix}+\begin{vmatrix}7&6\\4&5\end{vmatrix}+\begin{vmatrix}7&5\\3&7\end{vmatrix}+\begin{vmatrix}5&8\\6&7\end{vmatrix}=24$$
\subsection*{4}
Consider an nxn matrix $B = A+I\epsilon$.  It must be possible to reduce det(B) to the polynomial form $(\epsilon-\epsilon_1)...(\epsilon-\epsilon_n)$.  If $\epsilon_i=0$, $\epsilon>\epsilon_i$ and the $i'th$ is non-zero.  Otherwise, the magnitude of $\epsilon$ can be chosen to be less than that of $\epsilon_i$, making the term non-zero.  Thus, det(B) is non-zero.
\subsection*{5}
If A is non-singular, then it suffices to show that
$$det(A^{-1})det(\lambda I-AB) \equiv det(\lambda I-BA)det(A^{-1})$$
since determinants are not themselves matrices and therefore commute.  Equivalently,
$$det(A^{-1}\lambda I-B)\equiv det(\lambda I A^{-1}-B)$$
which is trivial, so we have the non-singular case.  If A is singular, then we replace it with $A+I\epsilon$ and its inverse with $(A+I\epsilon)^{-1}$ by a result of (4).  By the same method, this gives
$$det((A+I\epsilon)^{-1}\lambda I-B)\equiv det(\lambda I(A+I\epsilon)^{-1}-B)$$  as a sufficient condition for the theorem.  For arbitrarily small epsilon, this holds.  It follows that all the invariants of AB are the same as those of BA.
\section*{4.4}
\subsection*{5}
The new length of x is the same as $(\rho x, x)^{1/2}$ where $\rho$ is diagonal matrix whose ii'th entry is $\rho_{ii}$.  V preserves the new length if and only if
$$(\rho x, x)^{1/2} = (\rho Vx,Vx)^{1/2}$$
or 
$$(\rho x, x) = (\rho V x, V x)$$
or
$$x^*\rho^*x = x^*V^*\rho^*Vx$$
which is generally true if and only if 
$$V^*\rho^*V = \rho^*$$
or 
$$V^*\rho = \rho^*V^{-1}$$
or
$$V^{-1} = \rho^{*-1}V^*\rho^*$$
Because $\rho_i$ are all implicitly real and $\rho$ is diagonal, $\rho = \rho^*$, so we get
$$V^{-1} = \rho^{-1}V\rho$$
That is, any length-preserving V has this similarity transform between itself and its inverse.

\subsection*{6}
If U is unitary, then $U*C = A$, and $B=UU*A=A$.  Similarly, $A = U*B$ and $C = U*BU$.  It follows that $C* = UB*U*$ and $C*C = UB*BU*$.  Since $A = B$, $A*A = B*B$ and their traces are the same.  Since $C*C$ is a similarity transform of $B*B$, its trace is also the same. 
\end{document}

